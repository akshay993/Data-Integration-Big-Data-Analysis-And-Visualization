head(data3)
clen<-function(x){c(length(x))}
etable<-summaryBy(Impressions~scode+Gender+agecat,data=data1,FUN=clen)
###################### Problem suggested by professor in piazza ###########################
# link to code: http://rstudio-pubs-static.s3.amazonaws.com/3256_bb10db1440724dac8fa40da5e658ada5.html
TTM <- read.delim("../Test_Data/ggplotDataset.txt")
head(TTM)
tail(TTM)
# Plot the basic frame of the stacked bar chart.
library(ggplot2)
ggplot(data = TTM, aes(x = Type.of.Behavior, y = Sample.Size, fill = Stage.of.Change)) +
geom_bar(stat="identity")
# Flip the x axis and y axis so that t names of behavior can be seen
# clearly.
ggplot(data = TTM, aes(x = Type.of.Behavior, y = Sample.Size, fill = Stage.of.Change)) +
geom_bar(stat="identity") + coord_flip()
# Reorder the chunks so that they represent the logical order of stage
# progression.
TTM$Stage.of.Change <- factor(TTM$Stage.of.Change, levels = c("Precontemplation",
"Contemplation", "Preparation", "Action", "Maintenance"))
# Re-plot the chart under the newly assigned order by changing the 'fill'
# command.
ggplot(data = TTM, aes(x = Type.of.Behavior, y = Sample.Size, fill = factor(Stage.of.Change))) +
geom_bar(stat="identity") + coord_flip()
TTM <- read.delim("../Test_Data/ggplotDataset.txt")
head(TTM)
tail(TTM)
# Plot the basic frame of the stacked bar chart.
library(ggplot2)
ggplot(data = TTM, aes(x = Type.of.Behavior, y = Sample.Size, fill = Stage.of.Change)) +
geom_bar(stat="identity")
TTM <- read.delim("../Test_Data/ggplotDataset.txt")
TTM <- read.delim(file.choose())
View(TTM)
TTM <- read.delim(file.choose())
head(TTM)
tail(TTM)
# Plot the basic frame of the stacked bar chart.
library(ggplot2)
ggplot(data = TTM, aes(x = Type.of.Behavior, y = Sample.Size, fill = Stage.of.Change)) +
geom_bar(stat="identity")
# Flip the x axis and y axis so that t names of behavior can be seen
# clearly.
ggplot(data = TTM, aes(x = Type.of.Behavior, y = Sample.Size, fill = Stage.of.Change)) +
geom_bar(stat="identity") + coord_flip()
# Reorder the chunks so that they represent the logical order of stage
# progression.
TTM$Stage.of.Change <- factor(TTM$Stage.of.Change, levels = c("Precontemplation",
"Contemplation", "Preparation", "Action", "Maintenance"))
# Re-plot the chart under the newly assigned order by changing the 'fill'
# command.
ggplot(data = TTM, aes(x = Type.of.Behavior, y = Sample.Size, fill = factor(Stage.of.Change))) +
geom_bar(stat="identity") + coord_flip()
library(ggplot2)
ggplot(data = TTM, aes(x = Type.of.Behavior, y = Sample.Size, fill = Stage.of.Change)) +
geom_bar(stat="identity")
library(ggplot2)
ggplot(data = TTM, aes(x = Type.of.Behavior, y = Sample.Size, fill = Stage.of.Change)) +
geom_bar(stat="identity")
install.packages("twitteR")
library(twitteR)
install.packages("httpuv")
setup_twitter_oauth("VxJ6qp5XL3VTclBzMBsD1Ez1A", "owezT5IVRVG8nvkSHXxqq4t2McwPO6mxesJTGU2549yHTJbP8m")
install.packages("openssl")
setup_twitter_oauth("VxJ6qp5XL3VTclBzMBsD1Ez1A", "owezT5IVRVG8nvkSHXxqq4t2McwPO6mxesJTGU2549yHTJbP8m")
search.string <- "#flu"
no.of.tweets <- 100
search.string <- "#flu"
no.of.tweets <- 100
tweets <- searchTwitter(search.string, n=no.of.tweets, lang="en")
tweets
View(tweets)
rm(list =ls())
## loading libraries
library(twitteR)
library(ggplot2)
library(ggmap)
library(data.table)
## Setup oauth
setup_twitter_oauth("VxJ6qp5XL3VTclBzMBsD1Ez1A", "owezT5IVRVG8nvkSHXxqq4t2McwPO6mxesJTGU2549yHTJbP8m", "340449785-0AWt3nkBVvLlX7hbUFLl0fEqIKs47qUU7V5UnFWH", "qnaD0Pyp9jUXfwVb82RlSKikuvVi2MAWxp1J0mD1Fle4d")
search.string <- "flu"
no.of.tweets <- 5000
tweets <- searchTwitter(search.string, n=no.of.tweets, lang="en")
tweets = strip_retweets(tweets, strip_manual=TRUE, strip_mt=TRUE)
tweets <- twListToDF(tweets)
getwd()
getwd()
library(ggplot)
install.packages(ggplot)
install.packages("ggplot")
library("ggplot2", lib.loc="~/Library/R/3.4/library")
library("ggmap", lib.loc="~/Library/R/3.4/library")
library("ggplot2", lib.loc="/Library/Frameworks/R.framework/Versions/3.4/Resources/library")
library("ggmap", lib.loc="/Library/Frameworks/R.framework/Versions/3.4/Resources/library")
install.packages(c("ggplot2", "ggmap"))
library(ggplot)
library(ggplot2)
getwd()
data=read.csv("/Users/akshaychopra/Documents/Twitter-client-for-Data-Collection-and-Exploratory-Data-Analysis-/Lab1Part2/Data/Influenza National Summary/Inflenza National Summary.txt")
View(data)
View(data)
View(data)
View(data)
View(data)
View(data)
library(ggplot2)
data=read.csv("/Users/akshaychopra/Documents/Twitter-client-for-Data-Collection-and-Exploratory-Data-Analysis-/Lab1Part2/Data/Influenza National Summary/Inflenza National Summary.txt")
data=read.csv("/Users/akshaychopra/Documents/Twitter-client-for-Data-Collection-and-Exploratory-Data-Analysis-/Lab1Part2/Data/Influenza National Summary/Inflenza National Summary.txt")
data=read.table("/Users/akshaychopra/Documents/Twitter-client-for-Data-Collection-and-Exploratory-Data-Analysis-/Lab1Part2/Data/Influenza National Summary/Inflenza National Summary.txt"
,
sep="\t", header=TRUE)
View(data)
View(data)
plot(data$Week,geom="histogram")
plot(data$Week,data$Total,geom="histogram")
plot(data$Week,data$Total)
plot(data$Week,data$Total)
plot(data$Week,data$Total,ylab="Total", xlab="Week")
plot(data$Week,data$Total,ylab="Total", xlab="Week", main="Week vs Total")
plot(data$Week,data$Total,ylab="Total", xlab="Week", main="Week vs Total", col="red")
plot(data$Week,data$Total,ylab="Total", xlab="Week", main="Week vs Total", col="red" pch=16)
library(ggplot2)
plot(data$Week,data$Total,ylab="Total", xlab="Week", main="Week vs Total", col="red" pch ="16")
plot(data$Week,data$Total,ylab="Total", xlab="Week", main="Week vs Total", col="red", pch =16)
plot(data$Week,data$Total,ylab="Total", xlab="Week", main="Week vs Total", col="red", pch =22)
plot(data$Week~data$Total,ylab="Total", xlab="Week", main="Week vs Total", col="red", pch =22)
plot(data$Week,data$Total,ylab="Total", xlab="Week", main="Week vs Total", col="red", pch =22)
plot(data$Week~data$Total,ylab="Total", xlab="Week", main="Week vs Total", col="red", pch =22)
plot(data$Week~data$Total,ylab="Week", xlab="Total", main="Week vs Total", col="red", pch =22)
library(twitteR)
library(ggplot2)
library(ggmap)
library(data.table)
j<-1;
for (i in tweets_With_location$location){
loc <- i
if (stringi::stri_enc_mark(loc)=="ASCII"){
if (j==1){
locations <- geocode(loc)
}
if (j>1){
locations <- rbind(locations,geocode(loc))
}
j <- j+1
}
}
search.string <- "#flu"
no.of.tweets <- 1300
tweets <- searchTwitter(search.string, n=no.of.tweets, lang="en")
## Conversion of searched tweets to Data frame
tweets <- twListToDF(tweets)
## Saving collected data to a csv file - only the tweets collection this session
setwd("../data_collected")
Name=paste("New", no.of.tweets," Tweets Collected on ",Sys.time())
write.csv(tweets, file = Name)
setwd("../Scripts")
# Reading all tweets collected so far
CDF=read.csv("../data_collected/consolidated_Tweets_Total")
CDF<- subset(CDF, select = -c(X)) #removing column named X
# Creating a consolided data frame of all the tweets collected so far
consolidated_Tweets_Total=rbind(CDF,tweets)
consolidated_Tweets_Total <- unique( consolidated_Tweets_Total[ , 1:16 ] ) #remove duplicates
# Saving all Tweets Collected from day 1 to csv file
setwd("../data_collected")
write.csv(consolidated_Tweets_Total, file = "consolidated_Tweets_Total")
setwd("../Scripts")
getwd()
age<-c(23, 25, 24, 23, 21, 31, 32, 30,31, 30, 37, 35, 38, 37, 39, 42, 43, 45, 43, 45)
clust<-kmeans(age,centers=3)
View(clust)
View(clust)
plotcluster(age,clust$cluster)
# install package /library “class” for using knn
library("class", lib.loc="C:/Program Files/R/R-3.2.2/library")
age<-c(25,35,45,20,35,52,23,40,60,48,33)
loan<-c(40,60,80,20,120,18,95,62,100,220,150)
default<-c("N","N","N","N","Y","Y","Y","Y","Y","Y","Y")
def<-factor(default)
data =data.frame(age,loan,def)
n.points<-11
training<-sample(1:n.points, 8, replace=FALSE)
train<-subset(data[training,], select=c(age,loan))
testing<-setdiff(1:n.points,training)
test<-subset(data[testing,], select=c(age,loan))
cl<- data$def[training]
true.labels<-data$def[testing]
knn(train,test,cl,k=3)
testcase<-c(40,80)
knn(train,testcase,cl,k=3)
knn(train,testcase,cl,k=5)
#K-Means: or K-Centroids:
list1<-c(23, 25, 24, 23, 21, 31, 32, 30,31, 30, 37, 35, 38, 37, 39, 42, 43, 45, 43, 45)
centers<-c(20,30,40)
kmeans(list1,centers,algorithm=c("Hartigan-Wong"))
clear
clc
a<=0
a<-0
a<-5
b<-a%2
b<- a%2
b<-a/2
p<-c(1,2,3,4,5)
p<-c(1,2,3.5,'a',5)
p<-c(1,2,3,4,5)
q<-c(2.5,3.5)
x=c(1,2.5,3)
xy=c(1.5,2.5,3.1)
y=c(1.5,2.5,3.1,'a')
y=c(1.5,2.5,3.1,"a")
typeof(y)
typeof(x)
typeof(xp)
typeof(p)
typeof(q)
r<-list(p,q)
View(r)
View(r)
r[1]
r[1][1]
r
r[1]
r[1][1]
r[1][2]
r[1][0]
r[1]
r[2]
r[3]
r[[1][2]]
r[[1]]
r[[2]]
r[[3]]
r[[1]][1]
r[[1]][2]
r[[2]][2]
clc
r[1]
r[[1]
r[[1]]
r[[1,2]]
clc
typeof(r[1])
typeof(r[[1])
typeof(r[[1]])
typeof(r[[1]][1])
a=c(1,2,3,4,5)
a=c(1,2,3,4,)
a
length(a)
2^1024
-2^1024
a
length(a)<-4
a
length(a)<-7
a
a<-44
a
length(a)<-4
a
print(abc)
print('abc')
for(i in 1:10)
{}
for(i in 1:10)
{ print('hello')}
typeof(1)
v<-1:5
v
v[1]
v[[1]
s
v[[1]]
typeof(v[[1]])
typeof(v[1])
v<-seq(5,9 by 0.4)
v<-seq(5,9 ,by 0.4)
v<-seq(5,9, by =0.4)
v
v<-c('apple','orange')
v
v[1,2,3]
v[1]
v[c(1,2)]
v[c(1,2,3)]
v[1:2]
1:2
v[1 2 3]
v[1 2]
v[1: 2]
v<-c(1,2,3,4,5)
v<-list("red","blue",1:5)
v
names(v)<-c('r','b','n')
v
v$r
v$b
v$g
v$n
v[1]
v[[1]]
typeof(v[[1]])
typeof(v[1])
v$r<-rubble
v[[1]]<-rubble
View(v)
View(v)
v[[4]]<-'b'
v
v[3]<-'b'
v
v[[3]]<-'b'
v[[3]]<-6
a<-list('a','b')
c<-c(a,b)
c<-c(a,v)
View(c)
View(c)
View(c)
View(c)
View(v)
View(v)
View(c)
View(c)
x<-unlist(v)
y<-unlist(c)
y
x
x+y
a<-c(1,2,3)
a<-seq(1,3,by=1)
a
a[1]
a[2]
a[1:2]
a[c(1,2)]
b<-1:4
a
c<-a+b
a[4]<-NULL
a<-1:3
c<-a+b
a<-c(1:2)
b<-c(1:2)
a+b
a[3]<-0
a
a[3]<-0:0
a<-seq(1,2,by=1)
a<-c(1,2)
b<-c(1)
a+b
a<-c(1,2,3)
b<-c(1,2)
a+b
list_a<-list(1,2,3)
list_a<-list(1:2)
View(list_a)
View(list_a)
list_a<-list(c(1,5))
View(list_a)
list_a<-list(1,2,3,4,5
list_a<-list(1,2,3,4,5)
View(list_a)
View(list_a)
View(list_a)
View(list_a)
View(list_a)
View(list_a)
View(list_a)
list_a<-list(1,2,3,4,5)
View(list_a)
View(list_a)
c
b<-list_a[[1]]
c<-list_a[1]
View(c)
a<-list(1,2)
b<-list("x","y")
b<-list("x",y)
c<-c(a,b)
View(c)
c[1]
c[2]
c[3]
c[[1]][1]
c[[1]][2]
c[[1]][3]
a<-c(1,2,3)
b<-("x","y","z")
b<-c("x","y","z")
df<-data.frame(a,b)
View(df)
str(df)
df$a[2]
df$a[1]
df$a
df$a[4]
df[2,2]
View(df)
View(df)
df[2,1]
df[2,2]
df[2,3]
df[1,2]
df[1,]
df[3,]
typeof(df$b)
typeof(df[2])
df[2]
df$b
df[1]
df[2]
df[[2]
df[[2]]
typeof(df[[2]])
typeof(df[2]))
typeof(df[2])
df[2]
df[[2]]
a<-c(1,2,3)
a.length
setwd("~/Documents/Data-Integration-Big-Data-Analysis-And-Visualization/Part2/code/dataCollection")
library('RCurl')
library('XML')
library(Rcrawler)
library(stringr)
install.packages(RCurl)
install.packages("RCurl")
install.packages("XML")
install.packages("RCrawler")
install.packages("Rcrawler")
library('RCurl')
library('XML')
library(Rcrawler)
library(stringr)
## Read all articles collected so far
setwd("../../Data/NYTimes")
Articles <- read.csv("NYTimes_Articles_Total")
Articles <- subset(Articles, select = -c(X))
i=10
try(Data<-ContentScraper(Url = toString(Articles$web_url[i]),
XpathPatterns =c("//*/p[@class='story-body-text story-content']"),
#ExcludeXpathPat = c("//*/header[@id='story-header']",
#                    "//*/div[@class='story-interrupter']",
#                   "//*/div[@class='story-interrupter']",
#                  "//*/footer[@class='story-footer story-content']",
#                 "//*/section[@id='related-combined-coverage']",
#                "//*/div[@class='reader-satisfaction-survey prompt feedback-prompt story-content hidden']",
#               "//*/div[@id='story-meta-footer']"),
PatternsName = c("Content"),
ManyPerPattern = TRUE))
content <-data.frame(Data)
content$Content <- str_replace_all(content$Content, "[^[:alnum:]]", " ")  ## removes special characters
#wordcount <- length(unlist(strsplit(toString(content$Content[i])," "))) ## gets a count of the number of words in the article
#content <- cbind(content,wordcount)
content<-as.vector(t(as.matrix(content)))
content<-data.frame(paste(content, collapse = ''))
colnames(content) <- "content"
wordcount <- length(unlist(strsplit(toString(content$content)," "))) ## gets a count of the number of words in the article
content <- cbind(content,wordcount)
for (i in c(1:200)){
if (i==1){
try(Data<-ContentScraper(Url = toString(Articles$web_url[i]),
XpathPatterns =c("//*/p[@class='story-body-text story-content']"),
#ExcludeXpathPat = c("//*/header[@id='story-header']",
#                    "//*/div[@class='story-interrupter']",
#                   "//*/div[@class='story-interrupter']",
#                  "//*/footer[@class='story-footer story-content']",
#                 "//*/section[@id='related-combined-coverage']",
#                "//*/div[@class='reader-satisfaction-survey prompt feedback-prompt story-content hidden']",
#               "//*/div[@id='story-meta-footer']"),
PatternsName = c("Content"),
ManyPerPattern = TRUE))
content <-data.frame(Data)
content$Content <- str_replace_all(content$Content, "[^[:alnum:]]", " ")  ## removes special characters
#wordcount <- length(unlist(strsplit(toString(content$Content[i])," "))) ## gets a count of the number of words in the article
#content <- cbind(content,wordcount)
content<-as.vector(t(as.matrix(content)))
content<-data.frame(paste(content, collapse = ''))
colnames(content) <- "content"
wordcount <- length(unlist(strsplit(toString(content$content)," "))) ## gets a count of the number of words in the article
content <- cbind(content,wordcount)
}
if (i>1){
try(Data<-ContentScraper(Url = toString(Articles$web_url[i]),
XpathPatterns =c("//*/p[@class='story-body-text story-content']"),
#ExcludeXpathPat = c("//*/header[@id='story-header']",
#                    "//*/div[@class='story-interrupter']",
#                   "//*/div[@class='story-interrupter']",
#                  "//*/footer[@class='story-footer story-content']",
#                 "//*/section[@id='related-combined-coverage']",
#                "//*/div[@class='reader-satisfaction-survey prompt feedback-prompt story-content hidden']",
#               "//*/div[@id='story-meta-footer']"),
PatternsName = c("Content"),
ManyPerPattern = TRUE))
temp <- data.frame(Data)
temp$Content <- str_replace_all(temp$Content, "[^[:alnum:]]", " ") ##removes special characters
temp<-as.vector(t(as.matrix(temp)))
temp<-data.frame(paste(temp, collapse = ''))
colnames(temp) <- "content"
wordcount <- length(unlist(strsplit(toString(temp$content)," "))) ## gets a count of the number of words in the article
temp <- cbind(temp,wordcount)
content <- rbind(content,temp)
}
print(i)
}
## Eliminating duplicates caused by error handling
content = content[!duplicated(content$wordcount),]
## Saving the article extracted
setwd("../../Data")
write.table(content$content,"articlesTotal1.txt",col.names = F,row.names = F, quote = F)
